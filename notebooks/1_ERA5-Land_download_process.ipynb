{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mNQl_OJNtXf"
   },
   "source": [
    "# Download ERA5-Land Daily Aggregated time series averaged over an Area of Interest\n",
    "\n",
    "\n",
    "## Requirements: \n",
    "\n",
    "1. Google Earth Engine account. Sign up [here](https://earthengine.google.com/signup/).\n",
    "\n",
    "2. GIS file of the Area of Interest (AOI) boundaries (.shp, .gpkg, or other file readable by geopandas). \n",
    "\n",
    "3. Lapse rates calculated from monthly ERA5 air temperatures at varying pressure levels from [Rounce et al. (2023)](https://www.science.org/doi/10.1126/science.abo1324), downloadable from the [Carnegie Mellon repository](https://cmu.app.box.com/s/p8aiby5s9f3n6ycgmhknbgo4htk3pn9j/folder/124736593075) (\"ERA5_lapserates_monthly.nc\"). \n",
    "\n",
    "4. Digital elevation model (DEM) over the area of interest for applying lapse rates.\n",
    "\n",
    "5. ERA5 geopotential for estimating geoid heights and applying lapse rates. Downloadable from the [ERA5-Land Documentation](https://confluence.ecmwf.int/display/CKB/ERA5-Land%3A+data+documentation). See Parameter Listings and download links in Table 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4KGjaZBrNuJc"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate and initialize Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-u8ICnmNx1q"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define filters, etc. for ERA5-Land querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Paths to input files\n",
    "# Full path to study-sites\n",
    "study_sites_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/study-sites'\n",
    "# Full path to this code package\n",
    "code_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/glacier-snow-cover-analysis/'\n",
    "\n",
    "# -----Date range\n",
    "date_start = '2012-10-01'\n",
    "date_end = '2023-12-01'\n",
    "\n",
    "# -----Bands to extract from ERA5-Land\n",
    "# See all data bands in the GEE documentation here: \n",
    "# https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_LAND_DAILY_AGGR#bands\n",
    "bands = ['temperature_2m', \n",
    "         'total_precipitation_sum', \n",
    "         'snowfall_sum', \n",
    "         'snowmelt_sum'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and process data for multiple study sites\n",
    "\n",
    "### Load study site names\n",
    "\n",
    "Assumes all study sites start with \"RGI\" and are located in the same folder, `study-sites-path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab site names from \"RGI\" folder names\n",
    "rgi_ids = [rgi_id for rgi_id in sorted(os.listdir(study_sites_path)) if 'RGI' in rgi_id]\n",
    "# Filter to sites without ERA data\n",
    "rgi_ids = [rgi_id for rgi_id in rgi_ids if not \n",
    "           os.path.exists(os.path.join(study_sites_path, rgi_id, 'ERA', f'{rgi_id}_ERA5_daily_means.csv'))] \n",
    "print(f'Sites to run = {len(rgi_ids)}')\n",
    "rgi_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over sites, query GEE, and export ERA5-Land to Google Drive\n",
    "\n",
    "Go to your GEE Task Manager to monitor exports: https://code.earthengine.google.com/tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Iterate over sites\n",
    "for rgi_id in tqdm(rgi_ids):\n",
    "    print(rgi_id)\n",
    "    \n",
    "    # Define AOI file name\n",
    "    aoi_fn = os.path.join(study_sites_path, rgi_id, 'AOIs', f'{rgi_id}_outline.shp')\n",
    "        \n",
    "    # Load AOI and adjust for GEE querying\n",
    "    aoi = gpd.read_file(aoi_fn)\n",
    "    aoi = aoi.to_crs('EPSG:4326')\n",
    "    aoi_ee = ee.Geometry.Polygon(list(zip(aoi.geometry[0].exterior.coords.xy[0], \n",
    "                                          aoi.geometry[0].exterior.coords.xy[1])))\n",
    " \n",
    "    # Query GEE for the ERA5-Land dataset\n",
    "    era5 = (ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")\n",
    "             .filter(ee.Filter.date(date_start, date_end))\n",
    "             .filterBounds(aoi_ee)\n",
    "             .select(bands))\n",
    "\n",
    "    # Resample at 30 m resolution to improve clipping and averaging\n",
    "    scale = 30\n",
    "    def resample(image):\n",
    "        return (image\n",
    "                .resample('bicubic')\n",
    "                .reproject(crs=aoi_ee.projection(), scale=scale))\n",
    "    era5_interp = era5.map(resample)\n",
    "                        \n",
    "    # Clip to AOI\n",
    "    def clip_to_aoi(image):\n",
    "        return ee.Image(image.clip(aoi_ee.buffer(11e3)))\n",
    "    era5_interp = era5_interp.map(clip_to_aoi)\n",
    "    era5_heights_interp = clip_to_aoi(era5_heights_interp)\n",
    "\n",
    "    # Calculate band means over the AOI\n",
    "    def average_bands_over_aoi(image):\n",
    "        # Calculate the mean for all bands over the study area\n",
    "        mean_dict = image.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=aoi_ee,\n",
    "            scale=scale,  \n",
    "            bestEffort=True\n",
    "        )\n",
    "        # Convert the mean values dictionary to a list of property names\n",
    "        band_names = image.bandNames()\n",
    "        properties = band_names.map(lambda band: ee.String('mean_').cat(ee.String(band)))\n",
    "        # Create a dictionary of the mean values with new names prefixed by 'mean_'\n",
    "        mean_properties = ee.Dictionary.fromLists(properties, band_names.map(lambda band: mean_dict.get(band)))\n",
    "        # Create a feature with the system:time_start property and the mean values\n",
    "        return ee.Feature(None, mean_properties.set('system:time_start', image.get('system:time_start')))\n",
    "    era5_mean = era5_interp.map(average_bands_over_aoi)\n",
    "\n",
    "    # Export features to Drive as CSV\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=era5_mean,\n",
    "        description=f'{rgi_id}_ERA5-Land_daily_means',\n",
    "        fileNamePrefix=f'{rgi_id}_ERA5-Land_daily_means',\n",
    "        folder='ERA5-Land_Exports',\n",
    "        fileFormat='CSV'\n",
    "    )\n",
    "    task.start()\n",
    "\n",
    "print('\\nExports are a-go-go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process ERA5-Land exports\n",
    "\n",
    "Apply lapse rates to air temperatures using the ERA5 ground reference heights and a site DEM, calculate PDDs and annual sums.\n",
    "\n",
    "Download all CSVs and place into one folder: `downloads_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define path to your downloads\n",
    "downloads_path = '/Users/raineyaberle/Downloads/ERA5-Land_Exports/'\n",
    "\n",
    "# Grab file names\n",
    "fns = sorted(glob.glob(os.path.join(downloads_path, '*.csv')))\n",
    "# Grab RGI IDs from file names\n",
    "rgi_ids = [os.path.basename(fn)[0:14] for fn in fns]\n",
    "print(f'Number of files = {len(rgi_ids)}')\n",
    "rgi_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over site names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ERA5 geopotential\n",
    "era5_heights_fn = os.path.join(code_path, 'inputs-outputs', 'geo_1279l4_0.1x0.1.grib2_v4_unpack.nc')\n",
    "era5_heights = rxr.open_rasterio(era5_heights_fn).squeeze()\n",
    "era5_heights.rio.write_crs('EPSG:4326', inplace=True)\n",
    "# Convert to heights above the geoid\n",
    "era5_heights = era5_heights / 9.816\n",
    "\n",
    "# Load lapse rates\n",
    "lapse_rates_fn = os.path.join(study_sites_path, '..', 'Rounce_et_al_2023', 'ERA5_lapserates_monthly.nc')\n",
    "lapse_rates = xr.open_dataset(lapse_rates_fn)\n",
    "lapse_rates = lapse_rates.drop_dims('level')\n",
    "lapse_rates = lapse_rates.sel(time=slice(np.datetime64('2012-10-01'), None)) # subset time to speed up computations\n",
    "lapse_rates = lapse_rates.rename({'longitude': 'x', 'latitude': 'y'}) # rename coords for comparison with DEM\n",
    "lapse_rates.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "### Lapse rates only go to 2020-04-01, so extend to 2023 and use the mean \n",
    "lapse_rates = lapse_rates.sel(time=slice(None, \"2020-04-01\"))\n",
    "mean_data = lapse_rates[\"lapserate\"].mean(dim=\"time\")\n",
    "new_time = pd.date_range(str(lapse_rates.time.data.astype('datetime64[D]').max()), \n",
    "                         \"2023-12-31\", freq=\"M\")\n",
    "new_data = np.tile(mean_data.values[np.newaxis, :, :], (len(new_time), 1, 1))\n",
    "new_ds = xr.Dataset(\n",
    "    {\"lapserate\": ((\"time\", \"y\", \"x\"), new_data)},\n",
    "    coords={\"time\": new_time, \"y\": lapse_rates.coords[\"y\"], \"x\": lapse_rates.coords[\"x\"]},\n",
    ")\n",
    "extended_ds = xr.concat([lapse_rates, new_ds], dim=\"time\")\n",
    "lapse_rates = extended_ds.sortby(\"time\")\n",
    "\n",
    "# function to solve for optimal UTM zone\n",
    "def convert_wgs_to_utm(lon: float, lat: float):\n",
    "    \"\"\"\n",
    "    Return best UTM epsg-code based on WGS84 lat and lon coordinate pair\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lon: float\n",
    "        longitude coordinate\n",
    "    lat: float\n",
    "        latitude coordinate\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    epsg_code: str\n",
    "        optimal UTM zone, e.g. \"EPSG:32606\"\n",
    "    \"\"\"\n",
    "    utm_band = str((np.floor((lon + 180) / 6) % 60) + 1)\n",
    "    if len(utm_band) == 1:\n",
    "        utm_band = '0' + utm_band\n",
    "    if lat >= 0:\n",
    "        epsg_code = '326' + utm_band\n",
    "    else:\n",
    "        epsg_code = '327' + utm_band\n",
    "    return f\"EPSG:{epsg_code}\"\n",
    "\n",
    "\n",
    "# Iterate over RGI IDs\n",
    "for rgi_id in tqdm(rgi_ids):\n",
    "    # print(rgi_id)\n",
    "    era5_fn = [fn for fn in fns if rgi_id in fn][0]\n",
    "    \n",
    "    # Define path for outputs\n",
    "    out_path = os.path.join(study_sites_path, rgi_id, 'ERA')\n",
    "    if not os.path.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "    out_fn = os.path.join(out_path, os.path.basename(era5_fn))\n",
    "    if os.path.exists(out_fn):\n",
    "        continue\n",
    "    \n",
    "    # Load ERA5-Land daily means CSV\n",
    "    era5_df = pd.read_csv(era5_fn)\n",
    "    era5_df['system:index'] = pd.to_datetime(era5_df['system:index'], format='%Y%m%d')\n",
    "    era5_df.rename(columns={'system:index':'Date'}, inplace=True)\n",
    "    era5_df.drop(columns=['.geo', 'system:time_start'], inplace=True) # remove unwanted columns\n",
    "    \n",
    "    # Load AOI\n",
    "    aoi_fn = os.path.join(study_sites_path, rgi_id, 'AOIs', f'{rgi_id}_outline.shp')\n",
    "    aoi = gpd.read_file(aoi_fn)\n",
    "    aoi = aoi.to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # Load DEM\n",
    "    dem_fn = glob.glob(os.path.join(study_sites_path, rgi_id, 'DEMs', \"*.tif\"))[0]\n",
    "    dem = rxr.open_rasterio(dem_fn).squeeze()\n",
    "    dem = dem.rio.write_crs(\"EPSG:4326\")\n",
    "    if len(dem.data.ravel()) > 1e6: # downsample DEMs for really big glaciers\n",
    "        # reproject to UTM for coordinates in meters\n",
    "        epsg_utm = convert_wgs_to_utm(aoi.geometry[0].centroid.coords.xy[0][0], \n",
    "                                      aoi.geometry[0].centroid.coords.xy[1][0])\n",
    "        dem = dem.rio.reproject(epsg_utm)\n",
    "        # downsample\n",
    "        dem = dem.rio.reproject(resolution=(1000,1000), dst_crs=epsg_utm) \n",
    "    dem = dem.rio.reproject(\"EPSG:4326\") # make sure it's now in WGS84 lat lon projection\n",
    "    if 'band' in dem.dims:\n",
    "        dem = dem.isel(band=0)\n",
    "    # Clip DEM to AOI\n",
    "    dem = dem.rio.clip(aoi.geometry)      \n",
    "    # Remove wacky values\n",
    "    dem = xr.where((dem < 1e3) | (dem > 1e4), np.nan, dem)\n",
    "\n",
    "    # Shift longitudes to align with ERA5 heights grid\n",
    "    dem['x'] = dem['x'] + 360\n",
    "    dem.rio.write_crs('EPSG:4326', inplace=True)\n",
    "\n",
    "    # Difference ERA5 heights and DEM heights\n",
    "    era5_df['ERA5_height_mean_m'] = float(era5_heights.rio.reproject_match(dem).mean().values)\n",
    "    era5_df['DEM_height_mean_m'] = float(dem.mean().values)\n",
    "    era5_df['height_diff_mean_m'] = float((dem - era5_heights.rio.reproject_match(dem)).mean().values)\n",
    "\n",
    "    # Get average monthly lapse rates over site\n",
    "    lapse_rates_site = lapse_rates.rio.reproject_match(dem).mean(dim='x').mean(dim='y')\n",
    "    era5_df['lapse_rate_C/m'] = 0\n",
    "    for t in lapse_rates.time.data:\n",
    "        era5_df.loc[(era5_df['Date'].dt.year==pd.Timestamp(t).year) \n",
    "                    & (era5_df['Date'].dt.month==pd.Timestamp(t).month), 'lapse_rate_C/m'] = float(lapse_rates_site.sel(time=t).lapserate)\n",
    "\n",
    "    # Apply monthly lapse rates to temperatures\n",
    "    era5_df['mean_temperature_2m_C'] = era5_df['mean_temperature_2m'] - 273.15    \n",
    "    era5_df['mean_temperature_2m_C_adj'] = era5_df['mean_temperature_2m_C'] + (era5_df['lapse_rate_C/m'] * era5_df['height_diff_mean_m'])\n",
    "    \n",
    "    # Calculate positive degree days (PDDs)\n",
    "    if 'mean_temperature_2m_C_adj' in era5_df.keys():\n",
    "        def calculate_pdd(temp_C):\n",
    "            if temp_C > 0:\n",
    "                return temp_C\n",
    "            else:\n",
    "                return 0\n",
    "        era5_df['positive_degree_days'] = era5_df['mean_temperature_2m_C_adj'].apply(calculate_pdd)\n",
    "        # Calculate cumulative PDDs starting in January\n",
    "        era5_df['positive_degree_days_annual_cumsum'] = era5_df.groupby(era5_df['Date'].dt.year)['positive_degree_days'].cumsum()\n",
    "\n",
    "    # Calculate annual sums for other columns starting in October\n",
    "    # Add water year column\n",
    "    def calculate_water_year(date):\n",
    "        if pd.Timestamp(date).month >= 10:\n",
    "            return pd.Timestamp(date).year\n",
    "        else:\n",
    "            return pd.Timestamp(date).year - 1\n",
    "    era5_df['water_year'] = era5_df['Date'].apply(lambda x: calculate_water_year(x))\n",
    "    for column in era5_df.keys():\n",
    "        if ('precip' in column) | ('snowfall' in column) | ('snowmelt' in column):\n",
    "            era5_df[f'{column}_wateryear_cumsum'] = era5_df.groupby('water_year')[column].cumsum()\n",
    "            \n",
    "    # Save to file\n",
    "    era5_df.to_csv(out_fn, index=False)\n",
    "    print('Processed ERA5 data saved to file:', out_fn)\n",
    "\n",
    "    # Plot time series\n",
    "    plot_columns = [col for col in era5_df.keys() if (col!='Date') & ('height' not in col) & (col!='water_year')]\n",
    "    fig, ax = plt.subplots(len(plot_columns), 1, figsize=(8,4*len(plot_columns)))\n",
    "    for i, column in enumerate(plot_columns):\n",
    "        ax2 = ax[i].twinx()\n",
    "        ax2.set_ylabel('')\n",
    "        ax[i].plot(era5_df['Date'], era5_df[column], '-k')\n",
    "        ax[i].set_title(column)\n",
    "        ax[i].grid()\n",
    "    # Save figure to file\n",
    "    fig_fn = out_fn.replace('.csv', '.png')\n",
    "    fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPUSxvA9DdKOQi56SFRph5u",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "glacier-snow-cover-mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
