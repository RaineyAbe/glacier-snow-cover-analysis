{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess snowline altitude uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utility functions\n",
    "code_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/glacier-snow-cover-analysis/'\n",
    "sys.path.append(os.path.join(code_path, 'scripts'))\n",
    "import utils as f\n",
    "\n",
    "# Define path to study sites\n",
    "scm_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping'\n",
    "\n",
    "# Define path for outputs\n",
    "out_path = os.path.join(scm_path, 'dataset', 'analysis')\n",
    "\n",
    "# Get names of study sites\n",
    "rgi_ids = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(scm_path, 'study-sites', 'RGI*')))]\n",
    "rgi_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile SLA bounds (uncertainty) for all sites and classifications\n",
    "\n",
    "The original SLA was calculated by sampling the $1-AAR$ percentile of the DEM. For example, if the AAR is 0.8, the SLA is calculated as the 20th percentile of elevations over the glacier area. \n",
    "\n",
    "$P_{SLA} = 1-AAR$\n",
    "\n",
    "$SLA = P_{SLA}(DEM)$\n",
    "\n",
    "To estimate upper and lower bounds for SLA, identify \"misclassified\" pixels above and below the SLA, and use those to adjust the SLA percentile. \n",
    "\n",
    "For the upper bound, calculate the area of snow-free pixels above the SLA, convert that to a percentile relative to the total area, and add that to the original SLA percentile. Sample the $P_{upper}$ of the DEM.  \n",
    "\n",
    "$P_{upper} = \\frac{A_{snow free, above SLA}}{A_{glacier}} + P_{SLA}$\n",
    "\n",
    "$SLA_{upper} = P_{upper}(DEM)$\n",
    "\n",
    "For the lower bound, calculate the area of snow-covered pixels below the SLA, convert that to a percentile relative to the total area, and subtract that from the original SLA percentile. Sample the $P_{lower}$ of the DEM. \n",
    "\n",
    "$P_{lower} = -\\frac{A_{snow covered, below SLA}}{A_{glacier}} + P_{SLA}$\n",
    "\n",
    "$SLA_{lower} = P_{lower}(DEM)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file name\n",
    "sla_bounds_fn = os.path.join(out_path, 'SLA_uncertainty_analysis.nc')\n",
    "if not os.path.exists(sla_bounds_fn):\n",
    "    # Initialize results DataFrame\n",
    "    sla_bounds_list = []\n",
    "\n",
    "    # Iterate over sites\n",
    "    for rgi_id in tqdm(rgi_ids):\n",
    "        # Load snow cover stats\n",
    "        scs_fn = os.path.join(scm_path, 'study-sites', rgi_id, f\"{rgi_id}_classifications.zarr\")\n",
    "        scs = f.load_snow_cover_stats(scs_fn)\n",
    "        \n",
    "        # Subset to the SLA bounds\n",
    "        scs = scs[['time', 'SLA', 'SLA_lower_bound', 'SLA_upper_bound']]\n",
    "        scs = scs.assign_coords({'RGIId': [rgi_id]})\n",
    "\n",
    "        # Add to list\n",
    "        sla_bounds_list.append(scs)\n",
    "        \n",
    "    # Concatenate into one dataset\n",
    "    sla_bounds = xr.concat(sla_bounds_list, dim='time')\n",
    "    \n",
    "    # Save results to file\n",
    "    sla_bounds.to_netcdf(sla_bounds_fn)\n",
    "    print('SLA bounds saved to file:', sla_bounds_fn)\n",
    "    \n",
    "else:\n",
    "    sla_bounds = xr.open_dataset(sla_bounds_fn)\n",
    "\n",
    "# Add column for total range and describe stats\n",
    "sla_bounds['SLA_bounds_range'] = np.abs(sla_bounds['SLA_upper_bound'] - sla_bounds['SLA_lower_bound'])\n",
    "plt.hist(sla_bounds['SLA_bounds_range'], bins=100)\n",
    "plt.show()  \n",
    "\n",
    "sla_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsca",
   "language": "python",
   "name": "gsca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
