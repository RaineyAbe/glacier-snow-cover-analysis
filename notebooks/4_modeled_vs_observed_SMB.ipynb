{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa19aea-f65a-4694-aa1b-1c1c24efbf58",
   "metadata": {},
   "source": [
    "# Compare modeled and remotely-sensed surface mass balance\n",
    "\n",
    "Requires mass balance model outputs at each site from [PyGEM](https://github.com/PyGEM-Community/PyGEM) (Rounce et al., 2023), which can be downloaded form the Carnegie Mellon data repository.\n",
    "\n",
    "The files downloaded for this work were:\n",
    "- Monthly surface mass balance along glacier centerlines for 2000â€“2022: \"binned\", downloaded from [global_ERA5_2000_2022](https://cmu.app.box.com/s/rzk8aeasg40dd3p0xr3yngkc5c0m8kxt/folder/251139952066)\n",
    "- Calibrated model parameters (degree-day factors of snow and temperature biases): \"{RGI ID}_modelprms_dict.json\" files downloaded from [pygem_datasets > Calibration](https://cmu.app.box.com/s/p8aiby5s9f3n6ycgmhknbgo4htk3pn9j/folder/298954564072)\n",
    "\n",
    "All files were placed in a folder called \"Rounce_et_al_2023\", defined with the `model_path` variable below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10b4fc-0d6f-45af-b2ac-9c92269f5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import median_abs_deviation as MAD\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde12fe-197d-41a7-8ec0-5b0d34956a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for inputs and outputs\n",
    "scm_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/'\n",
    "model_path = os.path.join(scm_path, 'Rounce_et_al_2023')\n",
    "out_path = os.path.join(scm_path, 'dataset', 'model_comparison')\n",
    "\n",
    "# import utility functions\n",
    "code_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/glacier-snow-cover-analysis'\n",
    "figures_path = os.path.join(code_path, 'figures')\n",
    "sys.path.append(os.path.join(code_path, 'scripts'))\n",
    "import utils as f\n",
    "\n",
    "# Load glacier boundaries for RGI IDs\n",
    "aois_fn = os.path.join(scm_path, 'dataset', 'AOIs.gpkg')\n",
    "aois = gpd.read_file(aois_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc2430",
   "metadata": {},
   "source": [
    "## 1. Monthly snowline altitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d98cc",
   "metadata": {},
   "source": [
    "### Remotely-sensed SLAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c287520",
   "metadata": {},
   "outputs": [],
   "source": [
    "slas_obs_fn = os.path.join(out_path, 'monthly_SLAs_observed.nc')\n",
    "if not os.path.exists(slas_obs_fn):\n",
    "    # Initialize a list to store DataFrames\n",
    "    slas_obs_list = []\n",
    "    \n",
    "    # sample SLA observations +/- 1 week of the first of each month\n",
    "    tdelta = np.timedelta64(1, 'W')  \n",
    "\n",
    "    # Iterate over RGI IDs\n",
    "    for rgi_id in tqdm(sorted(aois['RGIId'].drop_duplicates().values)):\n",
    "        scs_fn = os.path.join(scm_path, 'study-sites', rgi_id, f'{rgi_id}_classifications.zarr')\n",
    "        scs = f.load_snow_cover_stats(scs_fn)\n",
    "        scs = scs.assign_coords({'Year': scs['time'].dt.isocalendar().year})\n",
    "        scs = scs.assign_coords({'Month': scs['time'].dt.month})\n",
    "        scs = scs.assign_coords({'Day': scs['time'].dt.day})\n",
    "        \n",
    "        # Grab monthly snowline altitude\n",
    "        dates = []\n",
    "        slas = []\n",
    "        nobs = []\n",
    "        for year, month in np.unique(np.array(list(zip(scs['Year'].values, scs['Month'].values))), axis=0):\n",
    "            target_time = np.datetime64(f'{year}-0{month}-01') if month < 10 else np.datetime64(f'{year}-{month}-01')\n",
    "            scs_near = scs.sel(time=(scs['time'] >= target_time - tdelta) & \n",
    "                                    (scs['time'] <= target_time + tdelta))\n",
    "            scs_near = scs_near.dropna(dim='time')\n",
    "            if len(scs_near['SLA'].values) > 0:\n",
    "                dates.append(target_time)\n",
    "                slas.append(float(scs_near['SLA'].mean().values))\n",
    "                nobs.append(len(scs_near['SLA'].values))\n",
    "        \n",
    "        scs_monthly = pd.DataFrame({'RGIId': [rgi_id]*len(dates), \n",
    "                                    'Date': dates,\n",
    "                                    'SLA_obs': slas,\n",
    "                                    'num_obs': nobs})\n",
    "        slas_obs_list.append(scs_monthly)\n",
    "    \n",
    "    # Combine all DataFrames\n",
    "    slas_obs = pd.concat(slas_obs_list)\n",
    "    \n",
    "    # Pivot\n",
    "    slas_obs_pivot = slas_obs.pivot(index='Date', columns='RGIId', values='SLA_obs')\n",
    "    slas_obs_pivot = slas_obs_pivot.sort_index()\n",
    "    \n",
    "    # Convert to xarray Dataset\n",
    "    slas_obs_xr = xr.Dataset(\n",
    "        {\"SLA_obs\": (['time', 'RGIId'], slas_obs_pivot.values)},\n",
    "        coords={\"time\": slas_obs_pivot.index.values,\n",
    "                \"RGIId\": slas_obs_pivot.columns.values}\n",
    "    )\n",
    "\n",
    "    # set attributes\n",
    "    slas_obs_xr['SLA_obs'].attrs['long_name'] = 'observed snowline altitude'\n",
    "    slas_obs_xr['SLA_obs'].attrs['units'] = 'meters above sea level'\n",
    "    \n",
    "    # Save to NetCDF file\n",
    "    slas_obs_xr.to_netcdf(slas_obs_fn)\n",
    "    print('Remotely-sensed monthly SLAs saved to file:', slas_obs_fn)\n",
    "\n",
    "else:\n",
    "    # Load from file\n",
    "    slas_obs_xr = xr.load_dataset(slas_obs_fn)\n",
    "    print('Remotely-sensed monthly SLAs loaded from file.')\n",
    "\n",
    "slas_obs_xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2c326-e946-4ec3-b453-2149a351f311",
   "metadata": {},
   "source": [
    "### Modeled SLAs and SMB at observed SLAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b26c4-b13f-4f05-b233-bd6e773bfdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if file already exists\n",
    "slas_mod_fn = os.path.join(out_path, 'monthly_SLAs_modeled.nc')\n",
    "if not os.path.exists(slas_mod_fn):\n",
    "    \n",
    "    # Initialize a list to store DataFrames\n",
    "    slas_mod_list = []\n",
    "    \n",
    "    # Iterate over sites\n",
    "    for rgi_id in tqdm(aois['RGIId'].drop_duplicates().values):\n",
    "        # Load modeled monthly SMB\n",
    "        smb_fn = glob.glob(os.path.join(model_path, 'glac_SMB_binned', f\"{rgi_id.split('RGI60-0')[1]}*.nc\"))[0]\n",
    "        smb = xr.open_dataset(smb_fn)\n",
    "        # calculate cumulative SMB\n",
    "        def water_year(date):\n",
    "            if date.month >= 10:\n",
    "                return date.year\n",
    "            else:\n",
    "                return date.year - 1\n",
    "        smb = smb.assign_coords({'water_year': (['time'], [water_year(t) for t in smb.time.values])})\n",
    "        smb['bin_massbalclim_monthly_cumsum'] = smb['bin_massbalclim_monthly'].groupby('water_year').cumsum()\n",
    "        smb['time'] = smb.time.values.astype('datetime64[D]')\n",
    "        h = smb['bin_surface_h_initial'].data.ravel()\n",
    "        \n",
    "        # Interpolate modeled SLA as where SMB = 0 and SMB at the observed SLA\n",
    "        slas = np.nan * np.zeros(len(smb.time.data))\n",
    "        smb_at_slas = np.nan * np.zeros(len(smb.time.data))\n",
    "        for j, t in enumerate(smb.time.data):\n",
    "            smb_time = smb.sel(time=t)['bin_massbalclim_monthly_cumsum'].data[0]\n",
    "            # when SMB <= 0 everywhere, set SLA to maximum glacier elevation\n",
    "            if np.all(smb_time <= 0):\n",
    "                slas[j] = np.max(h)\n",
    "            # when SMB >= 0 everywhere, set SLA to minimum glacier elevation\n",
    "            elif np.all(smb_time >= 0):\n",
    "                slas[j] = np.min(h)\n",
    "            # otherwise, linearly interpolate SLA\n",
    "            else:\n",
    "                sorted_indices = np.argsort(h)\n",
    "                slas[j] = np.interp(0, smb_time[sorted_indices], h[sorted_indices])\n",
    "            # interpolate the modeled SMB at the observed SLA\n",
    "            sla_obs = slas_obs.loc[(slas_obs['RGIId']==rgi_id) & (slas_obs['Date']==t), 'SLA_obs']\n",
    "            if len(sla_obs) > 0:\n",
    "                smb_at_slas[j] = np.interp(sla_obs.values[0], h, smb_time)\n",
    "\n",
    "        # Save results in dataframe\n",
    "        df = pd.DataFrame({'RGIId': [rgi_id]*len(smb.time.data),\n",
    "                            'Date': smb.time.data,\n",
    "                            'SLA_mod': slas,\n",
    "                            'SMB_at_SLA_obs': smb_at_slas})\n",
    "        # concatenate to dataframe list\n",
    "        slas_mod_list.append(df)\n",
    "        \n",
    "    # Combine all DataFrames\n",
    "    slas_mod = pd.concat(slas_mod_list)\n",
    "    \n",
    "    # Create xarray Dataset\n",
    "    slas_mod_pivot = slas_mod.pivot(index='Date', columns='RGIId', values=['SLA_mod', 'SMB_at_SLA_obs'])\n",
    "    slas_mod_pivot = slas_mod_pivot.sort_index()\n",
    "    \n",
    "    # Convert to xarray Dataset\n",
    "    slas_mod_xr = xr.Dataset(\n",
    "        {\"SLA_mod\": (['time', 'RGIId'], slas_mod_pivot['SLA_mod'].values),\n",
    "         \"SMB_at_SLA_obs\":(['time', 'RGIId'], slas_mod_pivot['SMB_at_SLA_obs'].values)},\n",
    "        coords={\"time\": slas_mod_pivot.index.values,\n",
    "                \"RGIId\": slas_mod_pivot.columns.levels[1].values}\n",
    "    )\n",
    "\n",
    "    # assign attributes\n",
    "    slas_mod_xr['SLA_mod'].attrs['long_name'] = 'modeled snowline altitude'\n",
    "    slas_mod_xr['SLA_mod'].attrs['units'] = 'meters above sea level'\n",
    "    slas_mod_xr['SMB_at_SLA_obs'].attrs['long_name'] = 'modeled surface mass balance at observed snowline altitude'\n",
    "    slas_mod_xr['SMB_at_SLA_obs'].attrs['units'] = 'meters water equivalent'\n",
    "\n",
    "    # Save to NetCDF file\n",
    "    slas_mod_xr.to_netcdf(slas_mod_fn)\n",
    "    print('Modeled monthly SLAs and snowline SMB saved to file:', slas_mod_fn)\n",
    "    \n",
    "else:\n",
    "    # Load from file\n",
    "    slas_mod_xr = xr.load_dataset(slas_mod_fn)\n",
    "    print('Modeled monthly SLAs loaded from file.')\n",
    "\n",
    "slas_mod_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6512e6fe",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file\n",
    "slas_merged_fn = os.path.join(out_path, 'monthly_SLAs_observed_modeled.nc')\n",
    "if not os.path.exists(slas_merged_fn):\n",
    "\n",
    "    # Merge modeled and remotely-sensed SLAs and modeled SMB at observed snowline\n",
    "    slas_merged = xr.merge([slas_obs_xr, slas_mod_xr])\n",
    "    \n",
    "    # Remove 2000-2012 (no observed values) and 2023 (no modeled values)\n",
    "    slas_merged.sel(time=slice(\"2013-01-01\",\"2023-01-01\"))\n",
    "    \n",
    "    # Remove observations outside May - November (no observed values)\n",
    "    def filter_month_range(month):\n",
    "        return (month >= 5) & (month <= 10)\n",
    "    slas_merged = slas_merged.sel(time=filter_month_range(slas_merged['time.month']))\n",
    "    \n",
    "    # Save results\n",
    "    slas_merged.to_netcdf(slas_merged_fn)\n",
    "    print('Merged monthly SLAs saved to file:', slas_merged_fn)\n",
    "\n",
    "else:\n",
    "    slas_merged = xr.load_dataset(slas_merged_fn)\n",
    "    print('Merged monthly SLAs loaded from file.')\n",
    "\n",
    "slas_diff = slas_merged['SLA_mod'] - slas_merged['SLA_obs']\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "ax.hist(slas_diff.values.ravel(), bins=50)\n",
    "ax.set_xlabel('SLA$_{mod}$ - SLA$_{obs}$ [m]')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "print('\\nDifference stats:')\n",
    "print(f'Mean diff = {np.nanmean(slas_diff.values)} m')\n",
    "print(f'Std. diff = {np.nanstd(slas_diff.values)} m')\n",
    "print(f'Median diff = {np.nanmedian(slas_diff.values)} m')\n",
    "print(f'MAD diff = {MAD(slas_diff.values.ravel(), nan_policy=\"omit\")} m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2ecd9",
   "metadata": {},
   "source": [
    "## 2. ELAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c401e-1035-42af-a623-2d6d03f8365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slas_elas_merged_fn = os.path.join(out_path, 'monthly_SLAs_annual_ELAs_observed_modeled.nc')\n",
    "\n",
    "if not os.path.exists(slas_elas_merged_fn):\n",
    "    # Make a copy of the SLAs\n",
    "    slas_elas_merged = slas_merged.copy()\n",
    "    \n",
    "    # Identify maximum annual observed SLAs\n",
    "    slas_elas_merged['ELA_obs'] = slas_elas_merged['SLA_obs'].groupby(['time.year']).max()\n",
    "    # Set ELAs before 2016 to NaN\n",
    "    slas_elas_merged['ELA_obs'] = xr.where(slas_elas_merged['ELA_obs'].year < 2016, np.nan, slas_elas_merged['ELA_obs'])\n",
    "    \n",
    "    # Identify maximum annual modeled SLAs \n",
    "    slas_elas_merged['ELA_mod'] = slas_elas_merged['SLA_mod'].groupby(['time.year']).max()\n",
    "    \n",
    "    # Set attributes\n",
    "    slas_elas_merged['ELA_obs'].attrs['units'] = 'meters above sea level'\n",
    "    slas_elas_merged['ELA_obs'].attrs['long_name'] = 'observed equilibrium line altitude'\n",
    "    slas_elas_merged['ELA_mod'].attrs['units'] = 'meters above sea level'\n",
    "    slas_elas_merged['ELA_mod'].attrs['long_name'] = 'modeled equilibrium line altitude'\n",
    "    slas_elas_merged.attrs['title'] = 'Observed and Modeled Snowline and Equilibrium Line Altitudes'\n",
    "    slas_elas_merged.attrs['description'] = (\n",
    "        'Time series of observed and modeled snowline altitudes (SLAs) and equilibrium line altitudes (ELAs). '\n",
    "        'Observed values were derived using the glacier-snow-cover-mapping pipeline, while modeled values '\n",
    "        'come from surface mass balance estimates produced by PyGEM (Rounce et al., 2023).'\n",
    "    )\n",
    "    slas_elas_merged.attrs['institution'] = 'Boise State University'\n",
    "    slas_elas_merged.attrs['references'] = 'doi:10.1029/2025GL115523'\n",
    "    slas_elas_merged.attrs['date_modified'] = '2025-06-07'\n",
    "    slas_elas_merged.attrs['time_coverage_start'] = '2013-05-01'\n",
    "    slas_elas_merged.attrs['time_coverage_end'] = '2023-10-31'\n",
    "    slas_elas_merged.attrs['horizontal_CRS'] = 'WGS84 (EPSG:4326)'\n",
    "    slas_elas_merged.attrs['vertical_CRS'] = 'EGM96 geoid (EPSG:5773)'\n",
    "    slas_elas_merged.attrs['model_source'] = 'PyGEMv1.0.1'\n",
    "    slas_elas_merged.attrs['model_institution'] = 'Carnegie Mellon University, Pittsburgh PA'\n",
    "    slas_elas_merged.attrs['model_history'] = 'Created by David Rounce (drounce@cmu.edu) on 2025-04-11'\n",
    "    slas_elas_merged.attrs['model_references'] = 'doi:10.1126/science.abo1324'\n",
    "\n",
    "\n",
    "    # Save to NetCDF file\n",
    "    slas_elas_merged.to_netcdf(slas_elas_merged_fn)\n",
    "    print('Merged SLAs and ELAs saved to file:', slas_elas_merged_fn)\n",
    "\n",
    "else:\n",
    "    slas_elas_merged = xr.load_dataset(slas_elas_merged_fn)\n",
    "    print('Merged SLAs and ELAs loaded from file.')\n",
    "\n",
    "slas_elas_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d85ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "slas_elas_merged['ELA_mod-obs'] = slas_elas_merged['ELA_mod'] - slas_elas_merged['ELA_obs']\n",
    "plt.hist(slas_elas_merged['ELA_mod-obs'].values.ravel(), bins=50)\n",
    "plt.show()\n",
    "\n",
    "print('\\nDifference stats:')\n",
    "print(f\"Mean diff = {np.nanmean(slas_elas_merged['ELA_mod-obs'].values)} m\")\n",
    "print(f\"Std. diff = {np.nanstd(slas_elas_merged['ELA_mod-obs'].values)} m\")\n",
    "print(f\"Median diff = {np.nanmedian(slas_elas_merged['ELA_mod-obs'].values)} m\")\n",
    "print(f\"MAD diff = {MAD(slas_elas_merged['ELA_mod-obs'].values.ravel(), nan_policy='omit')} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0a680",
   "metadata": {},
   "source": [
    "## 3. Assess agreement with new PyGEM runs at the USGS Benchmark Glaciers\n",
    "\n",
    "For remotely-sensed and modeled snowline time series, bin estimates by week of year, characterize the timing of snowline rise and fall and maximum snowline altitude. Select the PyGEM run that agrees best.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2207b9-784d-4d61-a34d-9599c61769db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plot_results = False  # Set to True to generate plots\n",
    "\n",
    "# Define paths\n",
    "summary_fn = os.path.join(out_path, 'PyGEM_comparison_summary.nc')\n",
    "pygem_new_path = os.path.join(scm_path, 'Brandon_new_PyGEM_runs')\n",
    "\n",
    "if not os.path.exists(summary_fn):\n",
    "    # Glacier identifiers and names\n",
    "    rgi_ids = [x for x in sorted(os.listdir(pygem_new_path)) if os.path.isdir(os.path.join(pygem_new_path, x))]\n",
    "    names = ['Gulkana', 'Wolverine', 'Lemon Creek', 'Sperry', 'South Cascade']\n",
    "    print('RGI IDs for glaciers with PyGEM runs:', rgi_ids)\n",
    "\n",
    "    # Initialize lists to collect structured outputs\n",
    "    glacier_ids = []\n",
    "    glacier_names = []\n",
    "    original_params = []\n",
    "    best_params = []\n",
    "    rmse_orig_all = []\n",
    "    rmse_best_all = []\n",
    "\n",
    "    for i, rgi_id in enumerate(rgi_ids):\n",
    "        name = names[i]\n",
    "        print(name, rgi_id)\n",
    "\n",
    "        # Get file names of model runs\n",
    "        run_fns = sorted(glob.glob(os.path.join(pygem_new_path, rgi_id, '*.nc')))\n",
    "        out_fn = os.path.join(out_path, f\"PyGEM_comparison_RGI60-0{rgi_id}.nc\")\n",
    "\n",
    "        # Load or build model dataset\n",
    "        if not os.path.exists(out_fn):\n",
    "            # Load observed snow cover data\n",
    "            scs_fn = os.path.join(scm_path, 'study-sites', f\"RGI60-0{rgi_id}\", f\"RGI60-0{rgi_id}_classifications.zarr\")\n",
    "            scs = f.load_snow_cover_stats(scs_fn)\n",
    "\n",
    "            # Iterate over model runs\n",
    "            model_runs_list = []\n",
    "            for fn in tqdm(run_fns):\n",
    "                ds = xr.open_dataset(fn)\n",
    "                ds['time'] = ds.indexes['time'].to_datetimeindex()\n",
    "                params = json.loads(ds.model_parameters)\n",
    "                run_ds = xr.Dataset({\n",
    "                    'SLA_mod': ds['glac_snowline_monthly'],\n",
    "                    'ELA_mod': ds['glac_ELA_annual'],\n",
    "                    'kp': xr.DataArray(params['kp'], dims=()),\n",
    "                    'tbias': xr.DataArray(params['tbias'], dims=()),\n",
    "                    'ddfsnow': xr.DataArray(params['ddfsnow'], dims=()),\n",
    "                })\n",
    "                model_runs_list.append(run_ds)\n",
    "\n",
    "            combined_ds = xr.concat(model_runs_list, dim='run')\n",
    "            combined_ds = combined_ds.sel(time=slice('2013-01-01', None))\n",
    "            combined_ds = combined_ds.sel(time=combined_ds['time.month'].isin([5, 6, 7, 8, 9, 10]))\n",
    "            combined_ds = xr.merge([combined_ds.isel(glac=0), slas_obs_xr.sel(RGIId=f\"RGI60-0{rgi_id}\")])\n",
    "\n",
    "            combined_ds.attrs.update({\n",
    "                'title': 'PyGEM Simulations with Parameter Variations and Observed Snowline Altitudes at USGS Benchmark Glaciers',\n",
    "                'description': 'Results from PyGEM simulations with varying model parameter values, combined with observed snowline altitudes at USGS Benchmark Glaciers.',\n",
    "                'institution': 'Boise State University',\n",
    "                'references': 'doi:10.1029/2025GL115523',\n",
    "                'vertical_CRS': 'EGM96 geoid (EPSG:5773)',\n",
    "                'date_modified': '2025-06-24',\n",
    "                'time_coverage_start': '2013-05-01',\n",
    "                'time_coverage_end': '2023-10-31'\n",
    "            })\n",
    "            combined_ds.to_netcdf(out_fn)\n",
    "        else:\n",
    "            combined_ds = xr.open_dataset(out_fn)\n",
    "\n",
    "        # Load original parameters\n",
    "        modelprms_fn = os.path.join(model_path, '..', 'Rounce_et_al_2023', 'modelprms', f\"{rgi_id}-modelprms_dict.pkl\")\n",
    "        modelprms = pd.read_pickle(modelprms_fn)\n",
    "\n",
    "        # Calculate RMSE and SLA difference\n",
    "        diff = combined_ds['SLA_mod'] - combined_ds['SLA_obs']\n",
    "        combined_ds['rmse'] = np.sqrt((diff**2).mean(dim='time'))\n",
    "        combined_ds['SLA_mod-obs'] = diff\n",
    "\n",
    "        # Best run based on lowest RMSE\n",
    "        df_plot = combined_ds[['tbias', 'ddfsnow', 'kp', 'rmse', 'SLA_mod-obs']].to_dataframe().reset_index()\n",
    "        df_plot = df_plot.dropna(subset=['rmse'])\n",
    "        df_plot_best = df_plot.loc[df_plot['rmse'].idxmin()]\n",
    "\n",
    "        # Find original run (closest param match)\n",
    "        squared_diffs = sum((combined_ds[var] - modelprms['emulator'][var][0])**2 for var in ['kp', 'tbias', 'ddfsnow'])\n",
    "        best_run_idx = squared_diffs.argmin(dim=\"run\")\n",
    "        combined_ds_original = combined_ds.sel(run=best_run_idx)\n",
    "        combined_ds_best = combined_ds.sel(run=int(df_plot_best['run']))\n",
    "\n",
    "        # Store structured summary\n",
    "        glacier_ids.append(f\"RGI60-0{rgi_id}\")\n",
    "        glacier_names.append(name)\n",
    "        original_params.append([\n",
    "            modelprms['emulator']['tbias'][0],\n",
    "            modelprms['emulator']['ddfsnow'][0],\n",
    "            modelprms['emulator']['kp'][0]\n",
    "        ])\n",
    "        best_params.append([\n",
    "            df_plot_best['tbias'],\n",
    "            df_plot_best['ddfsnow'],\n",
    "            df_plot_best['kp']\n",
    "        ])\n",
    "        rmse_orig = float(np.sqrt(((combined_ds_original['SLA_mod'] - combined_ds_original['SLA_obs'])**2).mean().item()))\n",
    "        rmse_best = float(np.sqrt(((combined_ds_best['SLA_mod'] - combined_ds_best['SLA_obs'])**2).mean().item()))\n",
    "        rmse_orig_all.append(rmse_orig)\n",
    "        rmse_best_all.append(rmse_best)\n",
    "\n",
    "        # Optional: Plotting\n",
    "        if plot_results:\n",
    "            fig, ax = plt.subplots(3, 1, figsize=(10, 8), gridspec_kw=dict(height_ratios=[2,2,1]))\n",
    "            sns.scatterplot(df_plot, x='tbias', y='ddfsnow', size='kp', hue='rmse', palette='viridis_r', sizes=(2,50), ax=ax[0])\n",
    "            ax[0].plot(modelprms['emulator']['tbias'], modelprms['emulator']['ddfsnow'], 's', markersize=15, markeredgecolor='m', markerfacecolor='None', markeredgewidth=2, label='Original')\n",
    "            ax[0].plot(df_plot_best['tbias'], df_plot_best['ddfsnow'], '*', markersize=15, markeredgecolor='m', markerfacecolor='None', markeredgewidth=2, label='Best')\n",
    "            ax[0].legend()\n",
    "            ax[0].set_title(f'{name} ({rgi_id})')\n",
    "            ax[0].grid(True)\n",
    "            ax[1].plot(combined_ds_original.time, combined_ds_original['SLA_mod'], '-', color='gray', label='Original')\n",
    "            ax[1].plot(combined_ds_best.time, combined_ds_best['SLA_mod'], '-k', label='Best')\n",
    "            ax[1].plot(scs['time'], scs['SLA'], '.m', markersize=5, label='Observed')\n",
    "            ax[1].legend()\n",
    "            ax[1].set_ylabel('Snowline altitude [m]')\n",
    "            ax[2].plot(combined_ds_original.time, combined_ds_original['SLA_mod-obs'], '.', color='gray', label='Original')\n",
    "            ax[2].plot(combined_ds_best.time, combined_ds_best['SLA_mod-obs'], '.', color='k', label='Best')\n",
    "            ax[2].legend()\n",
    "            ax[2].grid()\n",
    "            ax[2].set_ylabel('Modeled - Observed\\nSnowline Altitude [m]')\n",
    "            fig.tight_layout()\n",
    "            fig_fn = os.path.join(figures_path, f\"{rgi_id}_PyGEM_comparison.png\")\n",
    "            fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "            print('Saved figure:', fig_fn)\n",
    "            plt.close(fig)\n",
    "\n",
    "    # Construct final dataset\n",
    "    params = ['tbias', 'ddfsnow', 'kp']\n",
    "    summary_ds = xr.Dataset(\n",
    "        data_vars=dict(\n",
    "            param_original=(['RGIId', 'parameter'], np.array(original_params)),\n",
    "            param_best=(['RGIId', 'parameter'], np.array(best_params)),\n",
    "            rmse_original=(['RGIId'], np.array(rmse_orig_all)),\n",
    "            rmse_best=(['RGIId'], np.array(rmse_best_all)),\n",
    "        ),\n",
    "        coords=dict(\n",
    "            RGIId=('RGIId', glacier_ids),\n",
    "            parameter=('parameter', params),\n",
    "            glacier_name=('RGIId', glacier_names),\n",
    "        ),\n",
    "        attrs=dict(\n",
    "            title=\"PyGEM Parameter Comparison\",\n",
    "            description=\"Original and calibrated PyGEM parameters by glacier with associated RMSEs.\",\n",
    "            institution=\"Boise State University\",\n",
    "            references=\"doi:10.1029/2025GL115523\",\n",
    "            date_modified=\"2025-06-24\",\n",
    "            model_source='PyGEMv1.0.1',\n",
    "            model_institution='Carnegie Mellon University, Pittsburgh PA',\n",
    "            model_history='Created by David Rounce (drounce@cmu.edu) on 2025-04-11',\n",
    "            model_references='doi:10.1126/science.abo1324'\n",
    "        )\n",
    "    )\n",
    "    # add variable attributes\n",
    "    summary_ds['param_original'].attrs.update({\n",
    "        'long_name': 'Original PyGEM model parameter values',\n",
    "        'description': 'Values from the default (uncalibrated) PyGEM model setup for each glacier'\n",
    "    })\n",
    "    summary_ds['param_best'].attrs.update({\n",
    "        'long_name': 'Calibrated PyGEM model parameter values',\n",
    "        'description': (\n",
    "            'Best-fitting parameter values identified by selecting the PyGEM run that minimized the '\n",
    "            'root mean square error (RMSE) between observed and modeled monthly snowline altitudes'\n",
    "        )\n",
    "    })\n",
    "    summary_ds['rmse_original'].attrs.update({\n",
    "        'long_name': 'RMSE for original PyGEM run',\n",
    "        'units': 'meters',\n",
    "        'description': (\n",
    "            'Root mean square error (RMSE) between observed and modeled snowline altitudes for the PyGEM run '\n",
    "            'using original (default) parameters'\n",
    "        )\n",
    "    })\n",
    "    summary_ds['rmse_best'].attrs.update({\n",
    "        'long_name': 'RMSE for calibrated PyGEM run',\n",
    "        'units': 'meters',\n",
    "        'description': (\n",
    "            'Root mean square error (RMSE) between observed and modeled snowline altitudes for the PyGEM run '\n",
    "            'with best-fit (calibrated) parameters'\n",
    "        )\n",
    "    })\n",
    "\n",
    "    # Save to file\n",
    "    summary_ds.to_netcdf(summary_fn)\n",
    "    print('Results saved to file:', summary_fn)\n",
    "    \n",
    "else:\n",
    "    # Load from file\n",
    "    summary_ds = xr.open_dataset(summary_fn)\n",
    "    print('Results loaded from file.')\n",
    "\n",
    "summary_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fbee6-e6a5-4424-a616-5f73e6c6434d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsca",
   "language": "python",
   "name": "gsca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
